{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Detection (w/ pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------object_detection cfg------------------------------\n",
      "mode: object_detection\n",
      "dataset: avenue\n",
      "coi: [0, 1, 2, 3, 7]\n",
      "work_dir: /home/sha/datasets/working_directory/0/\n",
      "data_root: /home/sha/datasets/\n",
      "consecutive: 10\n",
      "save_image: False\n",
      "save_image_all: False\n",
      "train_od: False\n",
      "test_od: False\n",
      "is_save_train_pickle: False\n",
      "is_save_test_pickle: False\n",
      "is_load_train_pickle: False\n",
      "is_load_test_pickle: True\n",
      "train_data: /home/sha/datasets/avenue/training/frames/\n",
      "test_data: /home/sha/datasets/avenue/testing/frames/\n",
      "factor_x: 1.0\n",
      "factor_y: 1.0\n",
      "confidence: 0.7\n",
      "test_confidence: 0.6\n",
      "obj_size: (64, 64)\n",
      "max_w: 640\n",
      "max_h: 360\n",
      "\n",
      "cuda\n",
      "Using cache found in /home/sha/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2024-2-3 Python-3.8.18 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3090 Ti, 24248MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5l summary: 367 layers, 46533693 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "Save test object batches...\n",
      "[1] 01: 143 batches, last_batch.shape:torch.Size([8, 3, 10, 64, 64])\n",
      "[2] 02: 121 batches, last_batch.shape:torch.Size([3, 3, 10, 64, 64])\n",
      "[3] 03: 92 batches, last_batch.shape:torch.Size([5, 3, 10, 64, 64])\n",
      "[4] 04: 94 batches, last_batch.shape:torch.Size([2, 3, 10, 64, 64])\n",
      "[5] 05: 100 batches, last_batch.shape:torch.Size([3, 3, 10, 64, 64])\n",
      "[6] 06: 128 batches, last_batch.shape:torch.Size([8, 3, 10, 64, 64])\n",
      "[7] 07: 60 batches, last_batch.shape:torch.Size([6, 3, 10, 64, 64])\n",
      "[8] 08: 3 batches, last_batch.shape:torch.Size([4, 3, 10, 64, 64])\n",
      "[9] 09: 117 batches, last_batch.shape:torch.Size([2, 3, 10, 64, 64])\n",
      "[10] 10: 84 batches, last_batch.shape:torch.Size([4, 3, 10, 64, 64])\n",
      "[11] 11: 47 batches, last_batch.shape:torch.Size([8, 3, 10, 64, 64])\n",
      "[12] 12: 127 batches, last_batch.shape:torch.Size([7, 3, 10, 64, 64])\n",
      "[13] 13: 54 batches, last_batch.shape:torch.Size([4, 3, 10, 64, 64])\n",
      "[14] 14: 50 batches, last_batch.shape:torch.Size([6, 3, 10, 64, 64])\n",
      "[15] 15: 100 batches, last_batch.shape:torch.Size([5, 3, 10, 64, 64])\n",
      "[16] 16: 74 batches, last_batch.shape:torch.Size([7, 3, 10, 64, 64])\n",
      "[17] 17: 42 batches, last_batch.shape:torch.Size([9, 3, 10, 64, 64])\n",
      "[18] 18: 29 batches, last_batch.shape:torch.Size([9, 3, 10, 64, 64])\n",
      "[19] 19: 24 batches, last_batch.shape:torch.Size([9, 3, 10, 64, 64])\n",
      "[20] 20: 27 batches, last_batch.shape:torch.Size([9, 3, 10, 64, 64])\n",
      "[21] 21: 7 batches, last_batch.shape:torch.Size([8, 3, 10, 64, 64])\n",
      " |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.00% [21/21 03:47<00:00]\r"
     ]
    }
   ],
   "source": [
    "!python ObjectDetection/run.py --work_num=0 --consecutive=10 --dataset=avenue --is_load_test_pickle=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHTech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------object_detection cfg------------------------------\n",
      "mode: object_detection\n",
      "dataset: shanghai\n",
      "coi: [0, 1, 2, 3, 7]\n",
      "work_dir: /home/sha/datasets/working_directory/0/\n",
      "data_root: /home/sha/datasets/\n",
      "consecutive: 4\n",
      "save_image: False\n",
      "save_image_all: False\n",
      "train_od: False\n",
      "test_od: False\n",
      "is_save_train_pickle: False\n",
      "is_save_test_pickle: False\n",
      "is_load_train_pickle: False\n",
      "is_load_test_pickle: True\n",
      "train_data: /home/sha/datasets/shanghai/training/\n",
      "test_data: /home/sha/datasets/shanghai/testing/\n",
      "max_w: 856\n",
      "max_h: 480\n",
      "factor_x: 1.2\n",
      "factor_y: 1.2\n",
      "confidence: 0.8\n",
      "test_confidence: 0.6\n",
      "obj_size: (224, 224)\n",
      "\n",
      "cuda\n",
      "Using cache found in /home/sha/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2024-2-3 Python-3.8.18 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3090 Ti, 24248MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5l summary: 367 layers, 46533693 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "Save test object batches...\n",
      "[1] 01_0014: 66 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[2] 01_0015: 108 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[3] 01_0016: 84 batches, last_batch.shape:torch.Size([6, 3, 4, 224, 224])\n",
      "[4] 01_0025: 150 batches, last_batch.shape:torch.Size([2, 3, 4, 224, 224])\n",
      "[5] 01_0026: 126 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[6] 01_0027: 102 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[7] 01_0028: 114 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[8] 01_0029: 78 batches, last_batch.shape:torch.Size([6, 3, 4, 224, 224])\n",
      "[9] 01_0030: 102 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[10] 01_0051: 84 batches, last_batch.shape:torch.Size([1, 3, 4, 224, 224])\n",
      "[11] 01_0052: 84 batches, last_batch.shape:torch.Size([10, 3, 4, 224, 224])\n",
      "[12] 01_0053: 114 batches, last_batch.shape:torch.Size([7, 3, 4, 224, 224])\n",
      "[13] 01_0054: 144 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[14] 01_0055: 78 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[15] 01_0056: 132 batches, last_batch.shape:torch.Size([2, 3, 4, 224, 224])\n",
      "[16] 01_0063: 48 batches, last_batch.shape:torch.Size([5, 3, 4, 224, 224])\n",
      "[17] 01_0064: 72 batches, last_batch.shape:torch.Size([8, 3, 4, 224, 224])\n",
      "[18] 01_0073: 72 batches, last_batch.shape:torch.Size([2, 3, 4, 224, 224])\n",
      "[19] 01_0076: 66 batches, last_batch.shape:torch.Size([5, 3, 4, 224, 224])\n",
      "[20] 01_0129: 60 batches, last_batch.shape:torch.Size([1, 3, 4, 224, 224])\n",
      "[21] 01_0130: 84 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[22] 01_0131: 72 batches, last_batch.shape:torch.Size([1, 3, 4, 224, 224])\n",
      "[23] 01_0132: 66 batches, last_batch.shape:torch.Size([2, 3, 4, 224, 224])\n",
      "[24] 01_0133: 54 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[25] 01_0134: 108 batches, last_batch.shape:torch.Size([2, 3, 4, 224, 224])\n",
      "[26] 01_0135: 102 batches, last_batch.shape:torch.Size([1, 3, 4, 224, 224])\n",
      "[27] 01_0136: 132 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[28] 01_0138: 78 batches, last_batch.shape:torch.Size([2, 3, 4, 224, 224])\n",
      "[29] 01_0139: 54 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[30] 01_0140: 60 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[31] 01_0141: 78 batches, last_batch.shape:torch.Size([2, 3, 4, 224, 224])\n",
      "[32] 01_0162: 48 batches, last_batch.shape:torch.Size([6, 3, 4, 224, 224])\n",
      "[33] 01_0163: 66 batches, last_batch.shape:torch.Size([1, 3, 4, 224, 224])\n",
      "[34] 01_0177: 79 batches, last_batch.shape:torch.Size([2, 3, 4, 224, 224])\n",
      "[35] 02_0128: 114 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[36] 02_0161: 84 batches, last_batch.shape:torch.Size([6, 3, 4, 224, 224])\n",
      "[37] 02_0164: 90 batches, last_batch.shape:torch.Size([7, 3, 4, 224, 224])\n",
      "[38] 03_0031: 132 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[39] 03_0032: 102 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[40] 03_0033: 78 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[41] 03_0035: 96 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[42] 03_0036: 114 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[43] 03_0039: 120 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[44] 03_0041: 114 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[45] 03_0059: 108 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[46] 03_0060: 96 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[47] 03_0061: 60 batches, last_batch.shape:torch.Size([1, 3, 4, 224, 224])\n",
      "[48] 04_0001: 138 batches, last_batch.shape:torch.Size([1, 3, 4, 224, 224])\n",
      "[49] 04_0003: 234 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[50] 04_0004: 216 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[51] 04_0010: 126 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[52] 04_0011: 78 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[53] 04_0012: 90 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[54] 04_0013: 90 batches, last_batch.shape:torch.Size([2, 3, 4, 224, 224])\n",
      "[55] 04_0046: 132 batches, last_batch.shape:torch.Size([1, 3, 4, 224, 224])\n",
      "[56] 04_0050: 84 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[57] 05_0017: 108 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[58] 05_0018: 120 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[59] 05_0019: 162 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[60] 05_0020: 162 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[61] 05_0021: 102 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[62] 05_0022: 84 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[63] 05_0023: 192 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[64] 05_0024: 108 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[65] 06_0144: 60 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[66] 06_0145: 54 batches, last_batch.shape:torch.Size([5, 3, 4, 224, 224])\n",
      "[67] 06_0147: 66 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[68] 06_0150: 66 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[69] 06_0153: 54 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[70] 06_0155: 66 batches, last_batch.shape:torch.Size([1, 3, 4, 224, 224])\n",
      "[71] 07_0005: 102 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[72] 07_0006: 96 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[73] 07_0007: 120 batches, last_batch.shape:torch.Size([1, 3, 4, 224, 224])\n",
      "[74] 07_0008: 114 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[75] 07_0009: 78 batches, last_batch.shape:torch.Size([5, 3, 4, 224, 224])\n",
      "[76] 07_0047: 150 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[77] 07_0048: 60 batches, last_batch.shape:torch.Size([5, 3, 4, 224, 224])\n",
      "[78] 07_0049: 120 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[79] 08_0044: 78 batches, last_batch.shape:torch.Size([11, 3, 4, 224, 224])\n",
      "[80] 08_0058: 84 batches, last_batch.shape:torch.Size([9, 3, 4, 224, 224])\n",
      "[81] 08_0077: 114 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[82] 08_0078: 54 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[83] 08_0079: 60 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[84] 08_0080: 72 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[85] 08_0156: 84 batches, last_batch.shape:torch.Size([5, 3, 4, 224, 224])\n",
      "[86] 08_0157: 78 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[87] 08_0158: 84 batches, last_batch.shape:torch.Size([9, 3, 4, 224, 224])\n",
      "[88] 08_0159: 66 batches, last_batch.shape:torch.Size([6, 3, 4, 224, 224])\n",
      "[89] 08_0178: 66 batches, last_batch.shape:torch.Size([10, 3, 4, 224, 224])\n",
      "[90] 08_0179: 84 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[91] 09_0057: 90 batches, last_batch.shape:torch.Size([6, 3, 4, 224, 224])\n",
      "[92] 10_0037: 108 batches, last_batch.shape:torch.Size([2, 3, 4, 224, 224])\n",
      "[93] 10_0038: 60 batches, last_batch.shape:torch.Size([5, 3, 4, 224, 224])\n",
      "[94] 10_0042: 108 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[95] 10_0074: 150 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[96] 10_0075: 126 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[97] 11_0176: 84 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[98] 12_0142: 150 batches, last_batch.shape:torch.Size([2, 3, 4, 224, 224])\n",
      "[99] 12_0143: 66 batches, last_batch.shape:torch.Size([2, 3, 4, 224, 224])\n",
      "[100] 12_0148: 78 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[101] 12_0149: 60 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[102] 12_0151: 72 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[103] 12_0152: 90 batches, last_batch.shape:torch.Size([2, 3, 4, 224, 224])\n",
      "[104] 12_0154: 96 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[105] 12_0173: 54 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[106] 12_0174: 84 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[107] 12_0175: 66 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      " |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.00% [107/107 20:58<00:00]\r"
     ]
    }
   ],
   "source": [
    "!python ObjectDetection/run.py --work_num=0 --consecutive=4 --dataset=shanghai --is_load_test_pickle=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corridor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------object_detection cfg------------------------------\n",
      "mode: object_detection\n",
      "dataset: iitb\n",
      "coi: [0, 1, 2, 3, 7]\n",
      "work_dir: /home/sha/datasets/working_directory/0/\n",
      "data_root: /home/sha/datasets/\n",
      "consecutive: 4\n",
      "save_image: False\n",
      "save_image_all: False\n",
      "train_od: False\n",
      "test_od: False\n",
      "is_save_train_pickle: False\n",
      "is_save_test_pickle: False\n",
      "is_load_train_pickle: False\n",
      "is_load_test_pickle: True\n",
      "train_data: /home/sha/datasets/iitb/training/\n",
      "test_data: /home/sha/datasets/iitb/testing/\n",
      "max_w: 1920\n",
      "max_h: 1080\n",
      "factor_x: 1.0\n",
      "factor_y: 1.0\n",
      "confidence: 0.8\n",
      "test_confidence: 0.6\n",
      "obj_size: (224, 224)\n",
      "\n",
      "cuda\n",
      "Using cache found in /home/sha/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2024-2-3 Python-3.8.18 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3090 Ti, 24248MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5l summary: 367 layers, 46533693 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "Save test object batches...\n",
      " |--------------------| 0.00% [0/150 00:00<?]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 000209: 136 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[2] 000210: 58 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[3] 000211: 356 batches, last_batch.shape:torch.Size([6, 3, 4, 224, 224])\n",
      "[4] 000212: 112 batches, last_batch.shape:torch.Size([6, 3, 4, 224, 224])\n",
      "[5] 000213: 391 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[6] 000214: 95 batches, last_batch.shape:torch.Size([7, 3, 4, 224, 224])\n",
      "[7] 000215: 137 batches, last_batch.shape:torch.Size([5, 3, 4, 224, 224])\n",
      "[8] 000216: 511 batches, last_batch.shape:torch.Size([5, 3, 4, 224, 224])\n",
      "[9] 000217: 170 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[10] 000218: 129 batches, last_batch.shape:torch.Size([8, 3, 4, 224, 224])\n",
      "[11] 000219: 157 batches, last_batch.shape:torch.Size([5, 3, 4, 224, 224])\n",
      "[12] 000220: 208 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[13] 000221: 794 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[14] 000222: 255 batches, last_batch.shape:torch.Size([5, 3, 4, 224, 224])\n",
      "[15] 000223: 446 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[16] 000224: 159 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[17] 000225: 209 batches, last_batch.shape:torch.Size([12, 3, 4, 224, 224])\n",
      "[18] 000226: 212 batches, last_batch.shape:torch.Size([6, 3, 4, 224, 224])\n",
      "[19] 000227: 102 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[20] 000228: 106 batches, last_batch.shape:torch.Size([7, 3, 4, 224, 224])\n",
      "[21] 000229: 271 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[22] 000230: 158 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[23] 000231: 135 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[24] 000232: 658 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[25] 000233: 223 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[26] 000234: 131 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[27] 000235: 50 batches, last_batch.shape:torch.Size([2, 3, 4, 224, 224])\n",
      "[28] 000236: 324 batches, last_batch.shape:torch.Size([6, 3, 4, 224, 224])\n",
      "[29] 000237: 372 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[30] 000238: 23 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[31] 000239: 1647 batches, last_batch.shape:torch.Size([2, 3, 4, 224, 224])\n",
      "[32] 000240: 505 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[33] 000241: 719 batches, last_batch.shape:torch.Size([6, 3, 4, 224, 224])\n",
      "[34] 000242: 366 batches, last_batch.shape:torch.Size([5, 3, 4, 224, 224])\n",
      "[35] 000243: 237 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[36] 000244: 101 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[37] 000245: 234 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[38] 000246: 553 batches, last_batch.shape:torch.Size([2, 3, 4, 224, 224])\n",
      "[39] 000247: 137 batches, last_batch.shape:torch.Size([6, 3, 4, 224, 224])\n",
      "[40] 000248: 223 batches, last_batch.shape:torch.Size([6, 3, 4, 224, 224])\n",
      "[41] 000249: 117 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[42] 000250: 208 batches, last_batch.shape:torch.Size([1, 3, 4, 224, 224])\n",
      "[43] 000251: 379 batches, last_batch.shape:torch.Size([5, 3, 4, 224, 224])\n",
      "[44] 000252: 218 batches, last_batch.shape:torch.Size([1, 3, 4, 224, 224])\n",
      "[45] 000253: 181 batches, last_batch.shape:torch.Size([11, 3, 4, 224, 224])\n",
      "[46] 000254: 843 batches, last_batch.shape:torch.Size([6, 3, 4, 224, 224])\n",
      "[47] 000255: 577 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[48] 000256: 834 batches, last_batch.shape:torch.Size([7, 3, 4, 224, 224])\n",
      "[49] 000257: 226 batches, last_batch.shape:torch.Size([7, 3, 4, 224, 224])\n",
      "[50] 000258: 562 batches, last_batch.shape:torch.Size([5, 3, 4, 224, 224])\n",
      "[51] 000259: 154 batches, last_batch.shape:torch.Size([5, 3, 4, 224, 224])\n",
      "[52] 000260: 98 batches, last_batch.shape:torch.Size([6, 3, 4, 224, 224])\n",
      "[53] 000261: 79 batches, last_batch.shape:torch.Size([5, 3, 4, 224, 224])\n",
      "[54] 000262: 284 batches, last_batch.shape:torch.Size([5, 3, 4, 224, 224])\n",
      "[55] 000263: 655 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[56] 000264: 141 batches, last_batch.shape:torch.Size([7, 3, 4, 224, 224])\n",
      "[57] 000265: 315 batches, last_batch.shape:torch.Size([7, 3, 4, 224, 224])\n",
      "[58] 000266: 339 batches, last_batch.shape:torch.Size([7, 3, 4, 224, 224])\n",
      "[59] 000267: 195 batches, last_batch.shape:torch.Size([1, 3, 4, 224, 224])\n",
      "[60] 000268: 185 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[61] 000269: 131 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[62] 000270: 161 batches, last_batch.shape:torch.Size([9, 3, 4, 224, 224])\n",
      "[63] 000271: 389 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[64] 000272: 95 batches, last_batch.shape:torch.Size([1, 3, 4, 224, 224])\n",
      "[65] 000273: 330 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[66] 000274: 153 batches, last_batch.shape:torch.Size([1, 3, 4, 224, 224])\n",
      "[67] 000275: 166 batches, last_batch.shape:torch.Size([6, 3, 4, 224, 224])\n",
      "[68] 000276: 256 batches, last_batch.shape:torch.Size([5, 3, 4, 224, 224])\n",
      "[69] 000277: 637 batches, last_batch.shape:torch.Size([5, 3, 4, 224, 224])\n",
      "[70] 000278: 153 batches, last_batch.shape:torch.Size([2, 3, 4, 224, 224])\n",
      "[71] 000279: 270 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[72] 000280: 223 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[73] 000281: 134 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[74] 000282: 111 batches, last_batch.shape:torch.Size([7, 3, 4, 224, 224])\n",
      "[75] 000283: 677 batches, last_batch.shape:torch.Size([2, 3, 4, 224, 224])\n",
      "[76] 000284: 527 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[77] 000285: 145 batches, last_batch.shape:torch.Size([1, 3, 4, 224, 224])\n",
      "[78] 000286: 224 batches, last_batch.shape:torch.Size([1, 3, 4, 224, 224])\n",
      "[79] 000287: 277 batches, last_batch.shape:torch.Size([2, 3, 4, 224, 224])\n",
      "[80] 000288: 266 batches, last_batch.shape:torch.Size([1, 3, 4, 224, 224])\n",
      "[81] 000289: 312 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[82] 000290: 166 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[83] 000291: 1176 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[84] 000292: 642 batches, last_batch.shape:torch.Size([8, 3, 4, 224, 224])\n",
      "[85] 000293: 181 batches, last_batch.shape:torch.Size([5, 3, 4, 224, 224])\n",
      "[86] 000294: 141 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[87] 000295: 232 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[88] 000296: 238 batches, last_batch.shape:torch.Size([7, 3, 4, 224, 224])\n",
      "[89] 000297: 89 batches, last_batch.shape:torch.Size([8, 3, 4, 224, 224])\n",
      "[90] 000298: 287 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[91] 000299: 1898 batches, last_batch.shape:torch.Size([1, 3, 4, 224, 224])\n",
      "[92] 000300: 162 batches, last_batch.shape:torch.Size([2, 3, 4, 224, 224])\n",
      "[93] 000301: 806 batches, last_batch.shape:torch.Size([1, 3, 4, 224, 224])\n",
      "[94] 000302: 178 batches, last_batch.shape:torch.Size([6, 3, 4, 224, 224])\n",
      "[95] 000303: 774 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[96] 000304: 169 batches, last_batch.shape:torch.Size([5, 3, 4, 224, 224])\n",
      "[97] 000305: 106 batches, last_batch.shape:torch.Size([6, 3, 4, 224, 224])\n",
      "[98] 000306: 187 batches, last_batch.shape:torch.Size([2, 3, 4, 224, 224])\n",
      "[99] 000307: 148 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[100] 000308: 543 batches, last_batch.shape:torch.Size([12, 3, 4, 224, 224])\n",
      "[101] 000309: 206 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[102] 000310: 191 batches, last_batch.shape:torch.Size([7, 3, 4, 224, 224])\n",
      "[103] 000311: 73 batches, last_batch.shape:torch.Size([9, 3, 4, 224, 224])\n",
      "[104] 000312: 131 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[105] 000313: 265 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[106] 000314: 154 batches, last_batch.shape:torch.Size([8, 3, 4, 224, 224])\n",
      "[107] 000315: 178 batches, last_batch.shape:torch.Size([1, 3, 4, 224, 224])\n",
      "[108] 000316: 101 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[109] 000317: 242 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[110] 000318: 158 batches, last_batch.shape:torch.Size([11, 3, 4, 224, 224])\n",
      "[111] 000319: 161 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[112] 000320: 298 batches, last_batch.shape:torch.Size([6, 3, 4, 224, 224])\n",
      "[113] 000321: 209 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[114] 000322: 269 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[115] 000323: 24 batches, last_batch.shape:torch.Size([2, 3, 4, 224, 224])\n",
      "[116] 000324: 213 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[117] 000325: 183 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[118] 000326: 204 batches, last_batch.shape:torch.Size([1, 3, 4, 224, 224])\n",
      "[119] 000327: 248 batches, last_batch.shape:torch.Size([12, 3, 4, 224, 224])\n",
      "[120] 000328: 267 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[121] 000329: 319 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[122] 000330: 485 batches, last_batch.shape:torch.Size([2, 3, 4, 224, 224])\n",
      "[123] 000331: 494 batches, last_batch.shape:torch.Size([7, 3, 4, 224, 224])\n",
      "[124] 000332: 109 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[125] 000333: 162 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[126] 000334: 137 batches, last_batch.shape:torch.Size([8, 3, 4, 224, 224])\n",
      "[127] 000335: 106 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[128] 000336: 424 batches, last_batch.shape:torch.Size([5, 3, 4, 224, 224])\n",
      "[129] 000337: 128 batches, last_batch.shape:torch.Size([1, 3, 4, 224, 224])\n",
      "[130] 000338: 299 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[131] 000339: 354 batches, last_batch.shape:torch.Size([8, 3, 4, 224, 224])\n",
      "[132] 000340: 123 batches, last_batch.shape:torch.Size([2, 3, 4, 224, 224])\n",
      "[133] 000341: 511 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[134] 000342: 249 batches, last_batch.shape:torch.Size([5, 3, 4, 224, 224])\n",
      "[135] 000343: 1033 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[136] 000344: 224 batches, last_batch.shape:torch.Size([6, 3, 4, 224, 224])\n",
      "[137] 000345: 183 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[138] 000346: 819 batches, last_batch.shape:torch.Size([6, 3, 4, 224, 224])\n",
      "[139] 000347: 490 batches, last_batch.shape:torch.Size([6, 3, 4, 224, 224])\n",
      "[140] 000348: 138 batches, last_batch.shape:torch.Size([0, 3, 4, 224, 224])\n",
      "[141] 000349: 180 batches, last_batch.shape:torch.Size([6, 3, 4, 224, 224])\n",
      "[142] 000350: 182 batches, last_batch.shape:torch.Size([9, 3, 4, 224, 224])\n",
      "[143] 000351: 103 batches, last_batch.shape:torch.Size([1, 3, 4, 224, 224])\n",
      "[144] 000352: 133 batches, last_batch.shape:torch.Size([5, 3, 4, 224, 224])\n",
      "[145] 000353: 212 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[146] 000354: 441 batches, last_batch.shape:torch.Size([7, 3, 4, 224, 224])\n",
      "[147] 000355: 147 batches, last_batch.shape:torch.Size([2, 3, 4, 224, 224])\n",
      "[148] 000356: 163 batches, last_batch.shape:torch.Size([3, 3, 4, 224, 224])\n",
      "[149] 000357: 662 batches, last_batch.shape:torch.Size([4, 3, 4, 224, 224])\n",
      "[150] 000358: 394 batches, last_batch.shape:torch.Size([6, 3, 4, 224, 224])\n",
      " |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.00% [150/150 4:43:14<00:00]\r"
     ]
    }
   ],
   "source": [
    "!python ObjectDetection/run.py --work_num=0 --consecutive=4 --dataset=iitb --is_load_test_pickle=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VideoPatchCore (w/ memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------memorization cfg------------------------------\n",
      "mode: memorization\n",
      "dataset: avenue\n",
      "coi: [0, 1, 2, 3, 7]\n",
      "img_size: (224, 224)\n",
      "work_dir: /home/sha/datasets/working_directory/0/\n",
      "data_root: /home/sha/datasets/\n",
      "cnl_pool: 32\n",
      "consecutive: 10\n",
      "pool_for_sm: 4\n",
      "spatial_f_coreset: 0.01\n",
      "temporal_f_coreset: 0.01\n",
      "highlevel_f_coreset: 0.01\n",
      "eps_coreset: 0.9\n",
      "random_projection: False\n",
      "save_feature: True\n",
      "save_memory: False\n",
      "train_data: /home/sha/datasets/avenue/training/frames/\n",
      "test_data: /home/sha/datasets/avenue/testing/frames/\n",
      "obj_size: (64, 64)\n",
      "clip_model: RN101\n",
      "power_n: 4\n",
      "\n",
      "cuda\n",
      "Save test global features...\n",
      "[1] 01: 143 features, last_batch.shape:torch.Size([1, 1536, 10])\n",
      "[2] 02: 121 features, last_batch.shape:torch.Size([1, 1536, 10])\n",
      "[3] 03: 92 features, last_batch.shape:torch.Size([1, 1536, 10])\n",
      "[4] 04: 94 features, last_batch.shape:torch.Size([1, 1536, 10])\n",
      "[5] 05: 100 features, last_batch.shape:torch.Size([1, 1536, 10])\n",
      "[6] 06: 128 features, last_batch.shape:torch.Size([1, 1536, 10])\n",
      "[7] 07: 60 features, last_batch.shape:torch.Size([1, 1536, 10])\n",
      "[8] 08: 3 features, last_batch.shape:torch.Size([1, 1536, 10])\n",
      "[9] 09: 117 features, last_batch.shape:torch.Size([1, 1536, 10])\n",
      "[10] 10: 84 features, last_batch.shape:torch.Size([1, 1536, 10])\n",
      "[11] 11: 47 features, last_batch.shape:torch.Size([1, 1536, 10])\n",
      "[12] 12: 127 features, last_batch.shape:torch.Size([1, 1536, 10])\n",
      "[13] 13: 54 features, last_batch.shape:torch.Size([1, 1536, 10])\n",
      "[14] 14: 50 features, last_batch.shape:torch.Size([1, 1536, 10])\n",
      "[15] 15: 100 features, last_batch.shape:torch.Size([1, 1536, 10])\n",
      "[16] 16: 74 features, last_batch.shape:torch.Size([1, 1536, 10])\n",
      "[17] 17: 42 features, last_batch.shape:torch.Size([1, 1536, 10])\n",
      "[18] 18: 29 features, last_batch.shape:torch.Size([1, 1536, 10])\n",
      "[19] 19: 24 features, last_batch.shape:torch.Size([1, 1536, 10])\n",
      "[20] 20: 27 features, last_batch.shape:torch.Size([1, 1536, 10])\n",
      "[21] 21: 7 features, last_batch.shape:torch.Size([1, 1536, 10])\n",
      "Save test local features....00% [21/21 02:11<00:00]\n",
      "[1] 01: 143 features, last_batch.shape:torch.Size([8, 32, 10, 28, 28])\n",
      "[2] 02: 121 features, last_batch.shape:torch.Size([3, 32, 10, 28, 28])\n",
      "[3] 03: 92 features, last_batch.shape:torch.Size([5, 32, 10, 28, 28])\n",
      "[4] 04: 94 features, last_batch.shape:torch.Size([2, 32, 10, 28, 28])\n",
      "[5] 05: 100 features, last_batch.shape:torch.Size([3, 32, 10, 28, 28])\n",
      "[6] 06: 128 features, last_batch.shape:torch.Size([8, 32, 10, 28, 28])\n",
      "[7] 07: 60 features, last_batch.shape:torch.Size([6, 32, 10, 28, 28])\n",
      "[8] 08: 3 features, last_batch.shape:torch.Size([4, 32, 10, 28, 28])\n",
      "[9] 09: 117 features, last_batch.shape:torch.Size([2, 32, 10, 28, 28])\n",
      "[10] 10: 84 features, last_batch.shape:torch.Size([4, 32, 10, 28, 28])\n",
      "[11] 11: 47 features, last_batch.shape:torch.Size([8, 32, 10, 28, 28])\n",
      "[12] 12: 127 features, last_batch.shape:torch.Size([7, 32, 10, 28, 28])\n",
      "[13] 13: 54 features, last_batch.shape:torch.Size([4, 32, 10, 28, 28])\n",
      "[14] 14: 50 features, last_batch.shape:torch.Size([6, 32, 10, 28, 28])\n",
      "[15] 15: 100 features, last_batch.shape:torch.Size([5, 32, 10, 28, 28])\n",
      "[16] 16: 74 features, last_batch.shape:torch.Size([7, 32, 10, 28, 28])\n",
      "[17] 17: 42 features, last_batch.shape:torch.Size([9, 32, 10, 28, 28])\n",
      "[18] 18: 29 features, last_batch.shape:torch.Size([9, 32, 10, 28, 28])\n",
      "[19] 19: 24 features, last_batch.shape:torch.Size([9, 32, 10, 28, 28])\n",
      "[20] 20: 27 features, last_batch.shape:torch.Size([9, 32, 10, 28, 28])\n",
      "[21] 21: 7 features, last_batch.shape:torch.Size([8, 32, 10, 28, 28])\n",
      "0 01 -----------------| 0.00% [0/21 00:00<?]<00:00]\n",
      "1 02 -----------------| 4.76% [1/21 00:00<00:17]\n",
      "2 03 -----------------| 9.52% [2/21 00:01<00:15]\n",
      "3 04 -----------------| 14.29% [3/21 00:02<00:12]\n",
      "4 05 -----------------| 19.05% [4/21 00:02<00:11]\n",
      "5 06 â–ˆ----------------| 23.81% [5/21 00:03<00:10]\n",
      "6 07 â–ˆâ–ˆ---------------| 28.57% [6/21 00:03<00:09]\n",
      "7 08 â–ˆâ–ˆâ–ˆ--------------| 33.33% [7/21 00:04<00:08]\n",
      "8 09 â–ˆâ–ˆâ–ˆâ–ˆ-------------| 38.10% [8/21 00:04<00:07]\n",
      "9 10 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ------------| 42.86% [9/21 00:04<00:06]\n",
      "10 11 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-----------| 47.62% [10/21 00:05<00:05]\n",
      "11 12 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----------| 52.38% [11/21 00:05<00:05]\n",
      "12 13 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ---------| 57.14% [12/21 00:06<00:04]\n",
      "13 14 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--------| 61.90% [13/21 00:06<00:03]\n",
      "14 15 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-------| 66.67% [14/21 00:06<00:03]\n",
      "15 16 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ------| 71.43% [15/21 00:07<00:02]\n",
      "16 17 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-----| 76.19% [16/21 00:08<00:02]\n",
      "17 18 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----| 80.95% [17/21 00:08<00:01]\n",
      "18 19 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ---| 85.71% [18/21 00:08<00:01]\n",
      "19 20 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--| 90.48% [19/21 00:08<00:00]\n",
      "20 21 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-| 95.24% [20/21 00:09<00:00]\n",
      " |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.00% [21/21 00:09<00:00]\n",
      "spatial, temporal, sigma: 0.7 0.3 16\n",
      "best_auc_local: 0.9026141605641838\n",
      "\n",
      "local, global, sigma: 0.7 0.3 17\n",
      "best_auc_total: 0.9281762240542206\n"
     ]
    }
   ],
   "source": [
    "!python Memorization/run.py \\\n",
    "    --work_num=0 --consecutive=10 --dataset=avenue --cnl_pool=32 \\\n",
    "    --spatial_f_coreset=0.01 --temporal_f_coreset=0.01 --highlevel_f_coreset=0.01 \\\n",
    "    --save_memory=False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHTech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------memorization cfg------------------------------\n",
      "mode: memorization\n",
      "dataset: shanghai\n",
      "coi: [0, 1, 2, 3, 7]\n",
      "img_size: (224, 224)\n",
      "work_dir: /home/sha/datasets/working_directory/0/\n",
      "data_root: /home/sha/datasets/\n",
      "cnl_pool: 64\n",
      "consecutive: 4\n",
      "pool_for_sm: 4\n",
      "spatial_f_coreset: 0.25\n",
      "temporal_f_coreset: 0.25\n",
      "highlevel_f_coreset: 0.25\n",
      "eps_coreset: 0.9\n",
      "random_projection: False\n",
      "save_feature: True\n",
      "save_memory: False\n",
      "train_data: /home/sha/datasets/shanghai/training/\n",
      "test_data: /home/sha/datasets/shanghai/testing/\n",
      "obj_size: (224, 224)\n",
      "clip_model: RN101\n",
      "power_n: 2\n",
      "\n",
      "cuda\n",
      "Save test global features...\n",
      "[1] 01_0014: 66 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[2] 01_0015: 108 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[3] 01_0016: 84 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[4] 01_0025: 150 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[5] 01_0026: 126 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[6] 01_0027: 102 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[7] 01_0028: 114 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[8] 01_0029: 78 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[9] 01_0030: 102 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[10] 01_0051: 84 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[11] 01_0052: 84 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[12] 01_0053: 114 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[13] 01_0054: 144 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[14] 01_0055: 78 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[15] 01_0056: 132 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[16] 01_0063: 48 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[17] 01_0064: 72 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[18] 01_0073: 72 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[19] 01_0076: 66 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[20] 01_0129: 60 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[21] 01_0130: 84 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[22] 01_0131: 72 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[23] 01_0132: 66 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[24] 01_0133: 54 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[25] 01_0134: 108 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[26] 01_0135: 102 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[27] 01_0136: 132 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[28] 01_0138: 78 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[29] 01_0139: 54 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[30] 01_0140: 60 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[31] 01_0141: 78 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[32] 01_0162: 48 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[33] 01_0163: 66 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[34] 01_0177: 79 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[35] 02_0128: 114 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[36] 02_0161: 84 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[37] 02_0164: 90 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[38] 03_0031: 132 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[39] 03_0032: 102 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[40] 03_0033: 78 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[41] 03_0035: 96 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[42] 03_0036: 114 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[43] 03_0039: 120 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[44] 03_0041: 114 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[45] 03_0059: 108 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[46] 03_0060: 96 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[47] 03_0061: 60 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[48] 04_0001: 138 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[49] 04_0003: 234 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[50] 04_0004: 216 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[51] 04_0010: 126 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[52] 04_0011: 78 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[53] 04_0012: 90 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[54] 04_0013: 90 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[55] 04_0046: 132 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[56] 04_0050: 84 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[57] 05_0017: 108 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[58] 05_0018: 120 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[59] 05_0019: 162 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[60] 05_0020: 162 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[61] 05_0021: 102 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[62] 05_0022: 84 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[63] 05_0023: 192 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[64] 05_0024: 108 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[65] 06_0144: 60 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[66] 06_0145: 54 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[67] 06_0147: 66 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[68] 06_0150: 66 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[69] 06_0153: 54 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[70] 06_0155: 66 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[71] 07_0005: 102 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[72] 07_0006: 96 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[73] 07_0007: 120 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[74] 07_0008: 114 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[75] 07_0009: 78 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[76] 07_0047: 150 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[77] 07_0048: 60 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[78] 07_0049: 120 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[79] 08_0044: 78 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[80] 08_0058: 84 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[81] 08_0077: 114 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[82] 08_0078: 54 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[83] 08_0079: 60 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[84] 08_0080: 72 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[85] 08_0156: 84 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[86] 08_0157: 78 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[87] 08_0158: 84 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[88] 08_0159: 66 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[89] 08_0178: 66 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[90] 08_0179: 84 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[91] 09_0057: 90 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[92] 10_0037: 108 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[93] 10_0038: 60 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[94] 10_0042: 108 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[95] 10_0074: 150 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[96] 10_0075: 126 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[97] 11_0176: 84 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[98] 12_0142: 150 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[99] 12_0143: 66 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[100] 12_0148: 78 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[101] 12_0149: 60 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[102] 12_0151: 72 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[103] 12_0152: 90 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[104] 12_0154: 96 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[105] 12_0173: 54 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[106] 12_0174: 84 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[107] 12_0175: 66 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "Save test local features....00% [107/107 04:22<00:00]\n",
      "[1] 01_0014: 66 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[2] 01_0015: 108 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[3] 01_0016: 84 features, last_batch.shape:torch.Size([6, 64, 4, 28, 28])\n",
      "[4] 01_0025: 150 features, last_batch.shape:torch.Size([2, 64, 4, 28, 28])\n",
      "[5] 01_0026: 126 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[6] 01_0027: 102 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[7] 01_0028: 114 features, last_batch.shape:torch.Size([2, 64, 4, 28, 28])\n",
      "[8] 01_0029: 78 features, last_batch.shape:torch.Size([6, 64, 4, 28, 28])\n",
      "[9] 01_0030: 102 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[10] 01_0051: 84 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[11] 01_0052: 84 features, last_batch.shape:torch.Size([10, 64, 4, 28, 28])\n",
      "[12] 01_0053: 114 features, last_batch.shape:torch.Size([7, 64, 4, 28, 28])\n",
      "[13] 01_0054: 144 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[14] 01_0055: 78 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[15] 01_0056: 132 features, last_batch.shape:torch.Size([2, 64, 4, 28, 28])\n",
      "[16] 01_0063: 48 features, last_batch.shape:torch.Size([5, 64, 4, 28, 28])\n",
      "[17] 01_0064: 72 features, last_batch.shape:torch.Size([8, 64, 4, 28, 28])\n",
      "[18] 01_0073: 72 features, last_batch.shape:torch.Size([2, 64, 4, 28, 28])\n",
      "[19] 01_0076: 66 features, last_batch.shape:torch.Size([5, 64, 4, 28, 28])\n",
      "[20] 01_0129: 60 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[21] 01_0130: 84 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[22] 01_0131: 72 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[23] 01_0132: 66 features, last_batch.shape:torch.Size([2, 64, 4, 28, 28])\n",
      "[24] 01_0133: 54 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[25] 01_0134: 108 features, last_batch.shape:torch.Size([2, 64, 4, 28, 28])\n",
      "[26] 01_0135: 102 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[27] 01_0136: 132 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[28] 01_0138: 78 features, last_batch.shape:torch.Size([2, 64, 4, 28, 28])\n",
      "[29] 01_0139: 54 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[30] 01_0140: 60 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[31] 01_0141: 78 features, last_batch.shape:torch.Size([2, 64, 4, 28, 28])\n",
      "[32] 01_0162: 48 features, last_batch.shape:torch.Size([6, 64, 4, 28, 28])\n",
      "[33] 01_0163: 66 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[34] 01_0177: 79 features, last_batch.shape:torch.Size([2, 64, 4, 28, 28])\n",
      "[35] 02_0128: 114 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[36] 02_0161: 84 features, last_batch.shape:torch.Size([6, 64, 4, 28, 28])\n",
      "[37] 02_0164: 90 features, last_batch.shape:torch.Size([7, 64, 4, 28, 28])\n",
      "[38] 03_0031: 132 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[39] 03_0032: 102 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[40] 03_0033: 78 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[41] 03_0035: 96 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[42] 03_0036: 114 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[43] 03_0039: 120 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[44] 03_0041: 114 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[45] 03_0059: 108 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[46] 03_0060: 96 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[47] 03_0061: 60 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[48] 04_0001: 138 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[49] 04_0003: 234 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[50] 04_0004: 216 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[51] 04_0010: 126 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[52] 04_0011: 78 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[53] 04_0012: 90 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[54] 04_0013: 90 features, last_batch.shape:torch.Size([2, 64, 4, 28, 28])\n",
      "[55] 04_0046: 132 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[56] 04_0050: 84 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[57] 05_0017: 108 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[58] 05_0018: 120 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[59] 05_0019: 162 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[60] 05_0020: 162 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[61] 05_0021: 102 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[62] 05_0022: 84 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[63] 05_0023: 192 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[64] 05_0024: 108 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[65] 06_0144: 60 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[66] 06_0145: 54 features, last_batch.shape:torch.Size([5, 64, 4, 28, 28])\n",
      "[67] 06_0147: 66 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[68] 06_0150: 66 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[69] 06_0153: 54 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[70] 06_0155: 66 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[71] 07_0005: 102 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[72] 07_0006: 96 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[73] 07_0007: 120 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[74] 07_0008: 114 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[75] 07_0009: 78 features, last_batch.shape:torch.Size([5, 64, 4, 28, 28])\n",
      "[76] 07_0047: 150 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[77] 07_0048: 60 features, last_batch.shape:torch.Size([5, 64, 4, 28, 28])\n",
      "[78] 07_0049: 120 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[79] 08_0044: 78 features, last_batch.shape:torch.Size([11, 64, 4, 28, 28])\n",
      "[80] 08_0058: 84 features, last_batch.shape:torch.Size([9, 64, 4, 28, 28])\n",
      "[81] 08_0077: 114 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[82] 08_0078: 54 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[83] 08_0079: 60 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[84] 08_0080: 72 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[85] 08_0156: 84 features, last_batch.shape:torch.Size([5, 64, 4, 28, 28])\n",
      "[86] 08_0157: 78 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[87] 08_0158: 84 features, last_batch.shape:torch.Size([9, 64, 4, 28, 28])\n",
      "[88] 08_0159: 66 features, last_batch.shape:torch.Size([6, 64, 4, 28, 28])\n",
      "[89] 08_0178: 66 features, last_batch.shape:torch.Size([10, 64, 4, 28, 28])\n",
      "[90] 08_0179: 84 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[91] 09_0057: 90 features, last_batch.shape:torch.Size([6, 64, 4, 28, 28])\n",
      "[92] 10_0037: 108 features, last_batch.shape:torch.Size([2, 64, 4, 28, 28])\n",
      "[93] 10_0038: 60 features, last_batch.shape:torch.Size([5, 64, 4, 28, 28])\n",
      "[94] 10_0042: 108 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[95] 10_0074: 150 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[96] 10_0075: 126 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[97] 11_0176: 84 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[98] 12_0142: 150 features, last_batch.shape:torch.Size([2, 64, 4, 28, 28])\n",
      "[99] 12_0143: 66 features, last_batch.shape:torch.Size([2, 64, 4, 28, 28])\n",
      "[100] 12_0148: 78 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[101] 12_0149: 60 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[102] 12_0151: 72 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[103] 12_0152: 90 features, last_batch.shape:torch.Size([2, 64, 4, 28, 28])\n",
      "[104] 12_0154: 96 features, last_batch.shape:torch.Size([2, 64, 4, 28, 28])\n",
      "[105] 12_0173: 54 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[106] 12_0174: 84 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[107] 12_0175: 66 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "0 01_0014 ------------| 0.00% [0/107 00:00<?]6<00:00]\n",
      "1 01_0015 ------------| 0.93% [1/107 00:05<09:27]\n",
      "2 01_0016 ------------| 1.87% [2/107 00:08<07:42]\n",
      "3 01_0025 ------------| 2.80% [3/107 00:19<11:25]\n",
      "4 01_0026 ------------| 3.74% [4/107 00:27<11:59]\n",
      "5 01_0027 ------------| 4.67% [5/107 00:32<11:02]\n",
      "6 01_0028 ------------| 5.61% [6/107 00:38<10:46]\n",
      "7 01_0029 ------------| 6.54% [7/107 00:42<10:01]\n",
      "8 01_0030 ------------| 7.48% [8/107 00:48<10:06]\n",
      "9 01_0051 ------------| 8.41% [9/107 00:51<09:21]\n",
      "10 01_0052 -----------| 9.35% [10/107 00:54<08:48]\n",
      "11 01_0053 -----------| 10.28% [11/107 01:04<09:18]\n",
      "12 01_0054 -----------| 11.21% [12/107 01:12<09:34]\n",
      "13 01_0055 -----------| 12.15% [13/107 01:19<09:34]\n",
      "14 01_0056 -----------| 13.08% [14/107 01:23<09:14]\n",
      "15 01_0063 -----------| 14.02% [15/107 01:29<09:06]\n",
      "16 01_0064 -----------| 14.95% [16/107 01:33<08:53]\n",
      "17 01_0073 -----------| 15.89% [17/107 01:39<08:46]\n",
      "18 01_0076 -----------| 16.82% [18/107 01:41<08:23]\n",
      "19 01_0129 -----------| 17.76% [19/107 01:46<08:15]\n",
      "20 01_0130 -----------| 18.69% [20/107 01:48<07:51]\n",
      "21 01_0131 -----------| 19.63% [21/107 01:49<07:30]\n",
      "22 01_0132 -----------| 20.56% [22/107 01:54<07:23]\n",
      "23 01_0133 -----------| 21.50% [23/107 01:56<07:05]\n",
      "24 01_0134 -----------| 22.43% [24/107 01:58<06:50]\n",
      "25 01_0135 -----------| 23.36% [25/107 02:02<06:42]\n",
      "26 01_0136 -----------| 24.30% [26/107 02:05<06:30]\n",
      "27 01_0138 -----------| 25.23% [27/107 02:13<06:36]\n",
      "28 01_0139 -----------| 26.17% [28/107 02:19<06:33]\n",
      "29 01_0140 -----------| 27.10% [29/107 02:22<06:24]\n",
      "30 01_0141 -----------| 28.04% [30/107 02:26<06:15]\n",
      "31 01_0162 -----------| 28.97% [31/107 02:27<06:02]\n",
      "32 01_0163 -----------| 29.91% [32/107 02:30<05:53]\n",
      "33 01_0177 -----------| 30.84% [33/107 02:33<05:43]\n",
      "34 02_0128 -----------| 31.78% [34/107 02:36<05:35]\n",
      "35 02_0161 -----------| 32.71% [35/107 02:47<05:44]\n",
      "36 02_0164 -----------| 33.64% [36/107 02:54<05:43]\n",
      "37 03_0031 -----------| 34.58% [37/107 03:04<05:49]\n",
      "38 03_0032 -----------| 35.51% [38/107 03:07<05:39]\n",
      "39 03_0033 -----------| 36.45% [39/107 03:10<05:31]\n",
      "40 03_0035 -----------| 37.38% [40/107 03:11<05:21]\n",
      "41 03_0036 -----------| 38.32% [41/107 03:13<05:11]\n",
      "42 03_0039 -----------| 39.25% [42/107 03:17<05:05]\n",
      "43 03_0041 -----------| 40.19% [43/107 03:20<04:58]\n",
      "44 03_0059 -----------| 41.12% [44/107 03:23<04:51]\n",
      "45 03_0060 -----------| 42.06% [45/107 03:27<04:45]\n",
      "46 03_0061 -----------| 42.99% [46/107 03:29<04:38]\n",
      "47 04_0001 -----------| 43.93% [47/107 03:31<04:30]\n",
      "48 04_0003 -----------| 44.86% [48/107 03:36<04:26]\n",
      "49 04_0004 -----------| 45.79% [49/107 03:42<04:22]\n",
      "50 04_0010 -----------| 46.73% [50/107 03:48<04:20]\n",
      "51 04_0011 -----------| 47.66% [51/107 03:55<04:18]\n",
      "52 04_0012 -----------| 48.60% [52/107 03:59<04:13]\n",
      "53 04_0013 -----------| 49.53% [53/107 04:02<04:07]\n",
      "54 04_0046 â–ˆ----------| 50.47% [54/107 04:06<04:02]\n",
      "55 04_0050 â–ˆ----------| 51.40% [55/107 04:10<03:56]\n",
      "56 05_0017 â–ˆ----------| 52.34% [56/107 04:13<03:50]\n",
      "57 05_0018 â–ˆ----------| 53.27% [57/107 04:16<03:44]\n",
      "58 05_0019 â–ˆ----------| 54.21% [58/107 04:20<03:40]\n",
      "59 05_0020 â–ˆâ–ˆ---------| 55.14% [59/107 04:25<03:35]\n",
      "60 05_0021 â–ˆâ–ˆ---------| 56.07% [60/107 04:30<03:31]\n",
      "61 05_0022 â–ˆâ–ˆ---------| 57.01% [61/107 04:34<03:27]\n",
      "62 05_0023 â–ˆâ–ˆ---------| 57.94% [62/107 04:37<03:21]\n",
      "63 05_0024 â–ˆâ–ˆ---------| 58.88% [63/107 04:43<03:17]\n",
      "64 06_0144 â–ˆâ–ˆ---------| 59.81% [64/107 04:47<03:13]\n",
      "65 06_0145 â–ˆâ–ˆâ–ˆ--------| 60.75% [65/107 04:49<03:06]\n",
      "66 06_0147 â–ˆâ–ˆâ–ˆ--------| 61.68% [66/107 04:51<03:01]\n",
      "67 06_0150 â–ˆâ–ˆâ–ˆ--------| 62.62% [67/107 04:53<02:54]\n",
      "68 06_0153 â–ˆâ–ˆâ–ˆ--------| 63.55% [68/107 04:56<02:49]\n",
      "69 06_0155 â–ˆâ–ˆâ–ˆ--------| 64.49% [69/107 04:57<02:44]\n",
      "70 07_0005 â–ˆâ–ˆâ–ˆâ–ˆ-------| 65.42% [70/107 04:59<02:38]\n",
      "71 07_0006 â–ˆâ–ˆâ–ˆâ–ˆ-------| 66.36% [71/107 05:03<02:34]\n",
      "72 07_0007 â–ˆâ–ˆâ–ˆâ–ˆ-------| 67.29% [72/107 05:08<02:29]\n",
      "73 07_0008 â–ˆâ–ˆâ–ˆâ–ˆ-------| 68.22% [73/107 05:13<02:25]\n",
      "74 07_0009 â–ˆâ–ˆâ–ˆâ–ˆ-------| 69.16% [74/107 05:17<02:21]\n",
      "75 07_0047 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ------| 70.09% [75/107 05:19<02:16]\n",
      "76 07_0048 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ------| 71.03% [76/107 05:26<02:13]\n",
      "77 07_0049 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ------| 71.96% [77/107 05:27<02:07]\n",
      "78 08_0044 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ------| 72.90% [78/107 05:33<02:03]\n",
      "79 08_0058 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ------| 73.83% [79/107 05:43<02:01]\n",
      "80 08_0077 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ------| 74.77% [80/107 05:54<01:59]\n",
      "81 08_0078 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-----| 75.70% [81/107 06:04<01:57]\n",
      "82 08_0079 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-----| 76.64% [82/107 06:07<01:52]\n",
      "83 08_0080 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-----| 77.57% [83/107 06:11<01:47]\n",
      "84 08_0156 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-----| 78.50% [84/107 06:14<01:42]\n",
      "85 08_0157 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-----| 79.44% [85/107 06:21<01:38]\n",
      "86 08_0158 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----| 80.37% [86/107 06:23<01:33]\n",
      "87 08_0159 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----| 81.31% [87/107 06:31<01:29]\n",
      "88 08_0178 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----| 82.24% [88/107 06:36<01:25]\n",
      "89 08_0179 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----| 83.18% [89/107 06:40<01:20]\n",
      "90 09_0057 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----| 84.11% [90/107 06:43<01:16]\n",
      "91 10_0037 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ---| 85.05% [91/107 06:48<01:11]\n",
      "92 10_0038 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ---| 85.98% [92/107 06:53<01:07]\n",
      "93 10_0042 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ---| 86.92% [93/107 06:56<01:02]\n",
      "94 10_0074 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ---| 87.85% [94/107 07:00<00:58]\n",
      "95 10_0075 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ---| 88.79% [95/107 07:08<00:54]\n",
      "96 11_0176 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ---| 89.72% [96/107 07:13<00:49]\n",
      "97 12_0142 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--| 90.65% [97/107 07:16<00:45]\n",
      "98 12_0143 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--| 91.59% [98/107 07:22<00:40]\n",
      "99 12_0148 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--| 92.52% [99/107 07:23<00:35]\n",
      "100 12_0149 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--| 93.46% [100/107 07:25<00:31]\n",
      "101 12_0151 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--| 94.39% [101/107 07:29<00:26]\n",
      "102 12_0152 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-| 95.33% [102/107 07:31<00:22]\n",
      "103 12_0154 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-| 96.26% [103/107 07:35<00:17]\n",
      "104 12_0173 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-| 97.20% [104/107 07:38<00:13]\n",
      "105 12_0174 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-| 98.13% [105/107 07:40<00:08]\n",
      "106 12_0175 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-| 99.07% [106/107 07:41<00:04]\n",
      " |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.00% [107/107 07:43<00:00]\n",
      "spatial, temporal, sigma: 0.5 0.5 12\n",
      "best_auc_local: 0.8482460601236425\n",
      "\n",
      "local, global, sigma: 0.9 0.1 12\n",
      "best_auc_total: 0.8512775840278847\n"
     ]
    }
   ],
   "source": [
    "!python Memorization/run.py \\\n",
    "    --work_num=0 --consecutive=4 --dataset=shanghai --cnl_pool=64 \\\n",
    "    --spatial_f_coreset=0.25 --temporal_f_coreset=0.25 --highlevel_f_coreset=0.25 \\\n",
    "    --save_memory=False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corridor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------memorization cfg------------------------------\n",
      "mode: memorization\n",
      "dataset: iitb\n",
      "coi: [0, 1, 2, 3, 7]\n",
      "img_size: (224, 224)\n",
      "work_dir: /home/sha/datasets/working_directory/0/\n",
      "data_root: /home/sha/datasets/\n",
      "cnl_pool: 64\n",
      "consecutive: 4\n",
      "pool_for_sm: 4\n",
      "spatial_f_coreset: 0.1\n",
      "temporal_f_coreset: 0.1\n",
      "highlevel_f_coreset: 0.1\n",
      "eps_coreset: 0.9\n",
      "random_projection: False\n",
      "save_feature: True\n",
      "save_memory: False\n",
      "train_data: /home/sha/datasets/iitb/training/\n",
      "test_data: /home/sha/datasets/iitb/testing/\n",
      "obj_size: (224, 224)\n",
      "clip_model: RN101\n",
      "power_n: 1\n",
      "\n",
      "cuda\n",
      "Save test global features...\n",
      "[1] 000209: 136 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[2] 000210: 58 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[3] 000211: 356 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[4] 000212: 112 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[5] 000213: 391 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[6] 000214: 95 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[7] 000215: 137 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[8] 000216: 511 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[9] 000217: 170 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[10] 000218: 129 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[11] 000219: 157 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[12] 000220: 208 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[13] 000221: 794 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[14] 000222: 255 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[15] 000223: 446 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[16] 000224: 159 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[17] 000225: 209 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[18] 000226: 212 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[19] 000227: 102 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[20] 000228: 106 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[21] 000229: 271 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[22] 000230: 158 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[23] 000231: 135 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[24] 000232: 658 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[25] 000233: 223 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[26] 000234: 131 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[27] 000235: 50 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[28] 000236: 324 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[29] 000237: 372 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[30] 000238: 23 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[31] 000239: 1647 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[32] 000240: 505 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[33] 000241: 719 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[34] 000242: 366 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[35] 000243: 237 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[36] 000244: 101 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[37] 000245: 234 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[38] 000246: 553 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[39] 000247: 137 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[40] 000248: 223 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[41] 000249: 117 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[42] 000250: 208 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[43] 000251: 379 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[44] 000252: 218 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[45] 000253: 181 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[46] 000254: 843 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[47] 000255: 577 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[48] 000256: 834 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[49] 000257: 226 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[50] 000258: 562 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[51] 000259: 154 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[52] 000260: 98 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[53] 000261: 79 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[54] 000262: 284 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[55] 000263: 655 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[56] 000264: 141 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[57] 000265: 315 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[58] 000266: 339 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[59] 000267: 195 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[60] 000268: 185 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[61] 000269: 131 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[62] 000270: 161 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[63] 000271: 389 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[64] 000272: 95 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[65] 000273: 330 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[66] 000274: 153 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[67] 000275: 166 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[68] 000276: 256 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[69] 000277: 637 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[70] 000278: 153 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[71] 000279: 270 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[72] 000280: 223 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[73] 000281: 134 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[74] 000282: 111 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[75] 000283: 677 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[76] 000284: 527 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[77] 000285: 145 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[78] 000286: 224 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[79] 000287: 277 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[80] 000288: 266 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[81] 000289: 312 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[82] 000290: 166 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[83] 000291: 1176 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[84] 000292: 642 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[85] 000293: 181 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[86] 000294: 141 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[87] 000295: 232 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[88] 000296: 238 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[89] 000297: 89 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[90] 000298: 287 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[91] 000299: 1898 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[92] 000300: 162 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[93] 000301: 806 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[94] 000302: 178 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[95] 000303: 774 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[96] 000304: 169 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[97] 000305: 106 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[98] 000306: 187 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[99] 000307: 148 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[100] 000308: 543 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[101] 000309: 206 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[102] 000310: 191 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[103] 000311: 73 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[104] 000312: 131 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[105] 000313: 265 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[106] 000314: 154 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[107] 000315: 178 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[108] 000316: 101 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[109] 000317: 242 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[110] 000318: 158 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[111] 000319: 161 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[112] 000320: 298 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[113] 000321: 209 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[114] 000322: 269 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[115] 000323: 24 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[116] 000324: 213 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[117] 000325: 183 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[118] 000326: 204 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[119] 000327: 248 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[120] 000328: 267 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[121] 000329: 319 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[122] 000330: 485 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[123] 000331: 494 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[124] 000332: 109 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[125] 000333: 162 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[126] 000334: 137 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[127] 000335: 106 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[128] 000336: 424 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[129] 000337: 128 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[130] 000338: 299 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[131] 000339: 354 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[132] 000340: 123 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[133] 000341: 511 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[134] 000342: 249 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[135] 000343: 1033 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[136] 000344: 224 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[137] 000345: 183 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[138] 000346: 819 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[139] 000347: 490 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[140] 000348: 138 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[141] 000349: 180 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[142] 000350: 182 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[143] 000351: 103 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[144] 000352: 133 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[145] 000353: 212 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[146] 000354: 441 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[147] 000355: 147 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[148] 000356: 163 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[149] 000357: 662 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "[150] 000358: 394 features, last_batch.shape:torch.Size([1, 1536, 4])\n",
      "Save test local features....00% [150/150 50:19<00:00]\n",
      "[1] 000209: 136 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[2] 000210: 58 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[3] 000211: 356 features, last_batch.shape:torch.Size([6, 64, 4, 28, 28])\n",
      "[4] 000212: 112 features, last_batch.shape:torch.Size([6, 64, 4, 28, 28])\n",
      "[5] 000213: 391 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[6] 000214: 95 features, last_batch.shape:torch.Size([7, 64, 4, 28, 28])\n",
      "[7] 000215: 137 features, last_batch.shape:torch.Size([5, 64, 4, 28, 28])\n",
      "[8] 000216: 511 features, last_batch.shape:torch.Size([5, 64, 4, 28, 28])\n",
      "[9] 000217: 170 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[10] 000218: 129 features, last_batch.shape:torch.Size([8, 64, 4, 28, 28])\n",
      "[11] 000219: 157 features, last_batch.shape:torch.Size([5, 64, 4, 28, 28])\n",
      "[12] 000220: 208 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[13] 000221: 794 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[14] 000222: 255 features, last_batch.shape:torch.Size([5, 64, 4, 28, 28])\n",
      "[15] 000223: 446 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[16] 000224: 159 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[17] 000225: 209 features, last_batch.shape:torch.Size([12, 64, 4, 28, 28])\n",
      "[18] 000226: 212 features, last_batch.shape:torch.Size([6, 64, 4, 28, 28])\n",
      "[19] 000227: 102 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[20] 000228: 106 features, last_batch.shape:torch.Size([7, 64, 4, 28, 28])\n",
      "[21] 000229: 271 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[22] 000230: 158 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[23] 000231: 135 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[24] 000232: 658 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[25] 000233: 223 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[26] 000234: 131 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[27] 000235: 50 features, last_batch.shape:torch.Size([2, 64, 4, 28, 28])\n",
      "[28] 000236: 324 features, last_batch.shape:torch.Size([6, 64, 4, 28, 28])\n",
      "[29] 000237: 372 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[30] 000238: 23 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[31] 000239: 1647 features, last_batch.shape:torch.Size([2, 64, 4, 28, 28])\n",
      "[32] 000240: 505 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[33] 000241: 719 features, last_batch.shape:torch.Size([6, 64, 4, 28, 28])\n",
      "[34] 000242: 366 features, last_batch.shape:torch.Size([5, 64, 4, 28, 28])\n",
      "[35] 000243: 237 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[36] 000244: 101 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[37] 000245: 234 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[38] 000246: 553 features, last_batch.shape:torch.Size([2, 64, 4, 28, 28])\n",
      "[39] 000247: 137 features, last_batch.shape:torch.Size([6, 64, 4, 28, 28])\n",
      "[40] 000248: 223 features, last_batch.shape:torch.Size([6, 64, 4, 28, 28])\n",
      "[41] 000249: 117 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[42] 000250: 208 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[43] 000251: 379 features, last_batch.shape:torch.Size([5, 64, 4, 28, 28])\n",
      "[44] 000252: 218 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[45] 000253: 181 features, last_batch.shape:torch.Size([11, 64, 4, 28, 28])\n",
      "[46] 000254: 843 features, last_batch.shape:torch.Size([6, 64, 4, 28, 28])\n",
      "[47] 000255: 577 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[48] 000256: 834 features, last_batch.shape:torch.Size([7, 64, 4, 28, 28])\n",
      "[49] 000257: 226 features, last_batch.shape:torch.Size([7, 64, 4, 28, 28])\n",
      "[50] 000258: 562 features, last_batch.shape:torch.Size([5, 64, 4, 28, 28])\n",
      "[51] 000259: 154 features, last_batch.shape:torch.Size([5, 64, 4, 28, 28])\n",
      "[52] 000260: 98 features, last_batch.shape:torch.Size([6, 64, 4, 28, 28])\n",
      "[53] 000261: 79 features, last_batch.shape:torch.Size([5, 64, 4, 28, 28])\n",
      "[54] 000262: 284 features, last_batch.shape:torch.Size([5, 64, 4, 28, 28])\n",
      "[55] 000263: 655 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[56] 000264: 141 features, last_batch.shape:torch.Size([7, 64, 4, 28, 28])\n",
      "[57] 000265: 315 features, last_batch.shape:torch.Size([7, 64, 4, 28, 28])\n",
      "[58] 000266: 339 features, last_batch.shape:torch.Size([7, 64, 4, 28, 28])\n",
      "[59] 000267: 195 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[60] 000268: 185 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[61] 000269: 131 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[62] 000270: 161 features, last_batch.shape:torch.Size([9, 64, 4, 28, 28])\n",
      "[63] 000271: 389 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[64] 000272: 95 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[65] 000273: 330 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[66] 000274: 153 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[67] 000275: 166 features, last_batch.shape:torch.Size([6, 64, 4, 28, 28])\n",
      "[68] 000276: 256 features, last_batch.shape:torch.Size([5, 64, 4, 28, 28])\n",
      "[69] 000277: 637 features, last_batch.shape:torch.Size([5, 64, 4, 28, 28])\n",
      "[70] 000278: 153 features, last_batch.shape:torch.Size([2, 64, 4, 28, 28])\n",
      "[71] 000279: 270 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[72] 000280: 223 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[73] 000281: 134 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[74] 000282: 111 features, last_batch.shape:torch.Size([7, 64, 4, 28, 28])\n",
      "[75] 000283: 677 features, last_batch.shape:torch.Size([2, 64, 4, 28, 28])\n",
      "[76] 000284: 527 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[77] 000285: 145 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[78] 000286: 224 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[79] 000287: 277 features, last_batch.shape:torch.Size([2, 64, 4, 28, 28])\n",
      "[80] 000288: 266 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[81] 000289: 312 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[82] 000290: 166 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[83] 000291: 1176 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[84] 000292: 642 features, last_batch.shape:torch.Size([8, 64, 4, 28, 28])\n",
      "[85] 000293: 181 features, last_batch.shape:torch.Size([5, 64, 4, 28, 28])\n",
      "[86] 000294: 141 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[87] 000295: 232 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[88] 000296: 238 features, last_batch.shape:torch.Size([7, 64, 4, 28, 28])\n",
      "[89] 000297: 89 features, last_batch.shape:torch.Size([8, 64, 4, 28, 28])\n",
      "[90] 000298: 287 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[91] 000299: 1898 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[92] 000300: 162 features, last_batch.shape:torch.Size([2, 64, 4, 28, 28])\n",
      "[93] 000301: 806 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[94] 000302: 178 features, last_batch.shape:torch.Size([6, 64, 4, 28, 28])\n",
      "[95] 000303: 774 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[96] 000304: 169 features, last_batch.shape:torch.Size([5, 64, 4, 28, 28])\n",
      "[97] 000305: 106 features, last_batch.shape:torch.Size([6, 64, 4, 28, 28])\n",
      "[98] 000306: 187 features, last_batch.shape:torch.Size([2, 64, 4, 28, 28])\n",
      "[99] 000307: 148 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[100] 000308: 543 features, last_batch.shape:torch.Size([12, 64, 4, 28, 28])\n",
      "[101] 000309: 206 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[102] 000310: 191 features, last_batch.shape:torch.Size([7, 64, 4, 28, 28])\n",
      "[103] 000311: 73 features, last_batch.shape:torch.Size([9, 64, 4, 28, 28])\n",
      "[104] 000312: 131 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[105] 000313: 265 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[106] 000314: 154 features, last_batch.shape:torch.Size([8, 64, 4, 28, 28])\n",
      "[107] 000315: 178 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[108] 000316: 101 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[109] 000317: 242 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[110] 000318: 158 features, last_batch.shape:torch.Size([11, 64, 4, 28, 28])\n",
      "[111] 000319: 161 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[112] 000320: 298 features, last_batch.shape:torch.Size([6, 64, 4, 28, 28])\n",
      "[113] 000321: 209 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[114] 000322: 269 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[115] 000323: 24 features, last_batch.shape:torch.Size([2, 64, 4, 28, 28])\n",
      "[116] 000324: 213 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[117] 000325: 183 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[118] 000326: 204 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[119] 000327: 248 features, last_batch.shape:torch.Size([12, 64, 4, 28, 28])\n",
      "[120] 000328: 267 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[121] 000329: 319 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[122] 000330: 485 features, last_batch.shape:torch.Size([2, 64, 4, 28, 28])\n",
      "[123] 000331: 494 features, last_batch.shape:torch.Size([7, 64, 4, 28, 28])\n",
      "[124] 000332: 109 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[125] 000333: 162 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[126] 000334: 137 features, last_batch.shape:torch.Size([8, 64, 4, 28, 28])\n",
      "[127] 000335: 106 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[128] 000336: 424 features, last_batch.shape:torch.Size([5, 64, 4, 28, 28])\n",
      "[129] 000337: 128 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[130] 000338: 299 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[131] 000339: 354 features, last_batch.shape:torch.Size([8, 64, 4, 28, 28])\n",
      "[132] 000340: 123 features, last_batch.shape:torch.Size([2, 64, 4, 28, 28])\n",
      "[133] 000341: 511 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[134] 000342: 249 features, last_batch.shape:torch.Size([5, 64, 4, 28, 28])\n",
      "[135] 000343: 1033 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[136] 000344: 224 features, last_batch.shape:torch.Size([6, 64, 4, 28, 28])\n",
      "[137] 000345: 183 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[138] 000346: 819 features, last_batch.shape:torch.Size([6, 64, 4, 28, 28])\n",
      "[139] 000347: 490 features, last_batch.shape:torch.Size([6, 64, 4, 28, 28])\n",
      "[140] 000348: 138 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[141] 000349: 180 features, last_batch.shape:torch.Size([6, 64, 4, 28, 28])\n",
      "[142] 000350: 182 features, last_batch.shape:torch.Size([9, 64, 4, 28, 28])\n",
      "[143] 000351: 103 features, last_batch.shape:torch.Size([1, 64, 4, 28, 28])\n",
      "[144] 000352: 133 features, last_batch.shape:torch.Size([5, 64, 4, 28, 28])\n",
      "[145] 000353: 212 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[146] 000354: 441 features, last_batch.shape:torch.Size([7, 64, 4, 28, 28])\n",
      "[147] 000355: 147 features, last_batch.shape:torch.Size([2, 64, 4, 28, 28])\n",
      "[148] 000356: 163 features, last_batch.shape:torch.Size([3, 64, 4, 28, 28])\n",
      "[149] 000357: 662 features, last_batch.shape:torch.Size([4, 64, 4, 28, 28])\n",
      "[150] 000358: 394 features, last_batch.shape:torch.Size([6, 64, 4, 28, 28])\n",
      "0 000209 -------------| 0.00% [0/150 00:00<?]:38<00:00]\n",
      "1 000210 -------------| 0.67% [1/150 00:02<06:26]\n",
      "2 000211 -------------| 1.33% [2/150 00:03<04:37]\n",
      "3 000212 -------------| 2.00% [3/150 00:31<25:43]\n",
      "4 000213 -------------| 2.67% [4/150 00:35<21:42]\n",
      "5 000214 -------------| 3.33% [5/150 00:49<23:50]\n",
      "6 000215 -------------| 4.00% [6/150 00:52<21:04]\n",
      "7 000216 -------------| 4.67% [7/150 00:56<19:12]\n",
      "8 000217 -------------| 5.33% [8/150 01:14<22:08]\n",
      "9 000218 -------------| 6.00% [9/150 01:16<20:02]\n",
      "10 000219 ------------| 6.67% [10/150 01:21<19:05]\n",
      "11 000220 ------------| 7.33% [11/150 01:26<18:07]\n",
      "12 000221 ------------| 8.00% [12/150 01:30<17:17]\n",
      "13 000222 ------------| 8.67% [13/150 01:52<19:50]\n",
      "14 000223 ------------| 9.33% [14/150 02:04<20:07]\n",
      "15 000224 ------------| 10.00% [15/150 02:11<19:45]\n",
      "16 000225 ------------| 10.67% [16/150 02:20<19:40]\n",
      "17 000226 ------------| 11.33% [17/150 02:35<20:16]\n",
      "18 000227 ------------| 12.00% [18/150 02:40<19:36]\n",
      "19 000228 ------------| 12.67% [19/150 02:44<18:57]\n",
      "20 000229 ------------| 13.33% [20/150 02:52<18:40]\n",
      "21 000230 ------------| 14.00% [21/150 02:59<18:20]\n",
      "22 000231 ------------| 14.67% [22/150 03:02<17:41]\n",
      "23 000232 ------------| 15.33% [23/150 03:04<16:59]\n",
      "24 000233 ------------| 16.00% [24/150 03:27<18:07]\n",
      "25 000234 ------------| 16.67% [25/150 03:35<17:56]\n",
      "26 000235 ------------| 17.33% [26/150 03:40<17:31]\n",
      "27 000236 ------------| 18.00% [27/150 03:41<16:48]\n",
      "28 000237 ------------| 18.67% [28/150 03:52<16:51]\n",
      "29 000238 ------------| 19.33% [29/150 04:02<16:52]\n",
      "30 000239 ------------| 20.00% [30/150 04:03<16:12]\n",
      "31 000240 ------------| 20.67% [31/150 04:18<16:34]\n",
      "32 000241 ------------| 21.33% [32/150 04:51<17:53]\n",
      "33 000242 ------------| 22.00% [33/150 05:14<18:36]\n",
      "34 000243 ------------| 22.67% [34/150 05:21<18:17]\n",
      "35 000244 ------------| 23.33% [35/150 05:26<17:52]\n",
      "36 000245 ------------| 24.00% [36/150 05:28<17:19]\n",
      "37 000246 ------------| 24.67% [37/150 05:35<17:03]\n",
      "38 000247 ------------| 25.33% [38/150 05:49<17:10]\n",
      "39 000248 ------------| 26.00% [39/150 05:53<16:45]\n",
      "40 000249 ------------| 26.67% [40/150 05:57<16:24]\n",
      "41 000250 ------------| 27.33% [41/150 06:00<15:58]\n",
      "42 000251 ------------| 28.00% [42/150 06:11<15:54]\n",
      "43 000252 ------------| 28.67% [43/150 06:32<16:17]\n",
      "44 000253 ------------| 29.33% [44/150 06:36<15:56]\n",
      "45 000254 ------------| 30.00% [45/150 06:51<15:59]\n",
      "46 000255 ------------| 30.67% [46/150 07:33<17:04]\n",
      "47 000256 ------------| 31.33% [47/150 07:41<16:50]\n",
      "48 000257 ------------| 32.00% [48/150 08:19<17:40]\n",
      "49 000258 ------------| 32.67% [49/150 08:29<17:29]\n",
      "50 000259 ------------| 33.33% [50/150 08:55<17:50]\n",
      "51 000260 ------------| 34.00% [51/150 09:01<17:31]\n",
      "52 000261 ------------| 34.67% [52/150 09:06<17:10]\n",
      "53 000262 ------------| 35.33% [53/150 09:10<16:47]\n",
      "54 000263 ------------| 36.00% [54/150 09:29<16:53]\n",
      "55 000264 ------------| 36.67% [55/150 09:52<17:03]\n",
      "56 000265 ------------| 37.33% [56/150 09:57<16:42]\n",
      "57 000266 ------------| 38.00% [57/150 10:10<16:35]\n",
      "58 000267 ------------| 38.67% [58/150 10:28<16:36]\n",
      "59 000268 ------------| 39.33% [59/150 10:33<16:16]\n",
      "60 000269 ------------| 40.00% [60/150 10:39<15:59]\n",
      "61 000270 ------------| 40.67% [61/150 10:44<15:40]\n",
      "62 000271 ------------| 41.33% [62/150 10:55<15:29]\n",
      "63 000272 ------------| 42.00% [63/150 11:09<15:24]\n",
      "64 000273 ------------| 42.67% [64/150 11:12<15:03]\n",
      "65 000274 ------------| 43.33% [65/150 11:23<14:54]\n",
      "66 000275 ------------| 44.00% [66/150 11:29<14:37]\n",
      "67 000276 ------------| 44.67% [67/150 11:38<14:25]\n",
      "68 000277 â–ˆ-----------| 45.33% [68/150 11:47<14:13]\n",
      "69 000278 â–ˆ-----------| 46.00% [69/150 12:15<14:23]\n",
      "70 000279 â–ˆ-----------| 46.67% [70/150 12:20<14:05]\n",
      "71 000280 â–ˆ-----------| 47.33% [71/150 12:28<13:53]\n",
      "72 000281 â–ˆ-----------| 48.00% [72/150 12:35<13:37]\n",
      "73 000282 â–ˆ-----------| 48.67% [73/150 12:40<13:21]\n",
      "74 000283 â–ˆ-----------| 49.33% [74/150 12:46<13:07]\n",
      "75 000284 â–ˆâ–ˆ----------| 50.00% [75/150 13:03<13:03]\n",
      "76 000285 â–ˆâ–ˆ----------| 50.67% [76/150 13:24<13:03]\n",
      "77 000286 â–ˆâ–ˆ----------| 51.33% [77/150 13:28<12:46]\n",
      "78 000287 â–ˆâ–ˆ----------| 52.00% [78/150 13:34<12:31]\n",
      "79 000288 â–ˆâ–ˆ----------| 52.67% [79/150 13:43<12:20]\n",
      "80 000289 â–ˆâ–ˆ----------| 53.33% [80/150 13:50<12:06]\n",
      "81 000290 â–ˆâ–ˆ----------| 54.00% [81/150 13:56<11:52]\n",
      "82 000291 â–ˆâ–ˆ----------| 54.67% [82/150 14:01<11:37]\n",
      "83 000292 â–ˆâ–ˆâ–ˆ---------| 55.33% [83/150 14:40<11:50]\n",
      "84 000293 â–ˆâ–ˆâ–ˆ---------| 56.00% [84/150 15:13<11:57]\n",
      "85 000294 â–ˆâ–ˆâ–ˆ---------| 56.67% [85/150 15:18<11:42]\n",
      "86 000295 â–ˆâ–ˆâ–ˆ---------| 57.33% [86/150 15:21<11:25]\n",
      "87 000296 â–ˆâ–ˆâ–ˆ---------| 58.00% [87/150 15:29<11:13]\n",
      "88 000297 â–ˆâ–ˆâ–ˆ---------| 58.67% [88/150 15:36<10:59]\n",
      "89 000298 â–ˆâ–ˆâ–ˆ---------| 59.33% [89/150 15:40<10:44]\n",
      "90 000299 â–ˆâ–ˆâ–ˆâ–ˆ--------| 60.00% [90/150 15:50<10:33]\n",
      "91 000300 â–ˆâ–ˆâ–ˆâ–ˆ--------| 60.67% [91/150 16:25<10:38]\n",
      "92 000301 â–ˆâ–ˆâ–ˆâ–ˆ--------| 61.33% [92/150 16:30<10:24]\n",
      "93 000302 â–ˆâ–ˆâ–ˆâ–ˆ--------| 62.00% [93/150 17:18<10:36]\n",
      "94 000303 â–ˆâ–ˆâ–ˆâ–ˆ--------| 62.67% [94/150 17:26<10:23]\n",
      "95 000304 â–ˆâ–ˆâ–ˆâ–ˆ--------| 63.33% [95/150 17:51<10:20]\n",
      "96 000305 â–ˆâ–ˆâ–ˆâ–ˆ--------| 64.00% [96/150 18:05<10:10]\n",
      "97 000306 â–ˆâ–ˆâ–ˆâ–ˆ--------| 64.67% [97/150 18:10<09:55]\n",
      "98 000307 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-------| 65.33% [98/150 18:14<09:40]\n",
      "99 000308 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-------| 66.00% [99/150 18:17<09:25]\n",
      "100 000309 â–ˆâ–ˆâ–ˆâ–ˆ-------| 66.67% [100/150 18:47<09:23]\n",
      "101 000310 â–ˆâ–ˆâ–ˆâ–ˆ-------| 67.33% [101/150 18:53<09:10]\n",
      "102 000311 â–ˆâ–ˆâ–ˆâ–ˆ-------| 68.00% [102/150 19:01<08:57]\n",
      "103 000312 â–ˆâ–ˆâ–ˆâ–ˆ-------| 68.67% [103/150 19:05<08:42]\n",
      "104 000313 â–ˆâ–ˆâ–ˆâ–ˆ-------| 69.33% [104/150 19:08<08:28]\n",
      "105 000314 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ------| 70.00% [105/150 19:25<08:19]\n",
      "106 000315 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ------| 70.67% [106/150 19:36<08:08]\n",
      "107 000316 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ------| 71.33% [107/150 19:43<07:55]\n",
      "108 000317 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ------| 72.00% [108/150 19:44<07:40]\n",
      "109 000318 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ------| 72.67% [109/150 19:52<07:28]\n",
      "110 000319 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ------| 73.33% [110/150 20:05<07:18]\n",
      "111 000320 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ------| 74.00% [111/150 20:11<07:05]\n",
      "112 000321 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ------| 74.67% [112/150 20:24<06:55]\n",
      "113 000322 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-----| 75.33% [113/150 20:33<06:43]\n",
      "114 000323 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-----| 76.00% [114/150 20:41<06:32]\n",
      "115 000324 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-----| 76.67% [115/150 20:42<06:18]\n",
      "116 000325 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-----| 77.33% [116/150 20:53<06:07]\n",
      "117 000326 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-----| 78.00% [117/150 21:03<05:56]\n",
      "118 000327 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-----| 78.67% [118/150 21:15<05:45]\n",
      "119 000328 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-----| 79.33% [119/150 21:39<05:38]\n",
      "120 000329 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----| 80.00% [120/150 21:48<05:27]\n",
      "121 000330 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----| 80.67% [121/150 21:58<05:16]\n",
      "122 000331 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----| 81.33% [122/150 22:10<05:05]\n",
      "123 000332 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----| 82.00% [123/150 22:28<04:55]\n",
      "124 000333 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----| 82.67% [124/150 22:32<04:43]\n",
      "125 000334 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----| 83.33% [125/150 22:37<04:31]\n",
      "126 000335 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----| 84.00% [126/150 22:43<04:19]\n",
      "127 000336 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----| 84.67% [127/150 22:44<04:07]\n",
      "128 000337 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ---| 85.33% [128/150 23:00<03:57]\n",
      "129 000338 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ---| 86.00% [129/150 23:07<03:45]\n",
      "130 000339 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ---| 86.67% [130/150 23:13<03:34]\n",
      "131 000340 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ---| 87.33% [131/150 23:32<03:24]\n",
      "132 000341 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ---| 88.00% [132/150 23:35<03:12]\n",
      "133 000342 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ---| 88.67% [133/150 23:56<03:03]\n",
      "134 000343 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ---| 89.33% [134/150 24:01<02:52]\n",
      "135 000344 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--| 90.00% [135/150 24:16<02:41]\n",
      "136 000345 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--| 90.67% [136/150 24:21<02:30]\n",
      "137 000346 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--| 91.33% [137/150 24:33<02:19]\n",
      "138 000347 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--| 92.00% [138/150 25:03<02:10]\n",
      "139 000348 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--| 92.67% [139/150 25:23<02:00]\n",
      "140 000349 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--| 93.33% [140/150 25:27<01:49]\n",
      "141 000350 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--| 94.00% [141/150 25:33<01:37]\n",
      "142 000351 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--| 94.67% [142/150 25:45<01:27]\n",
      "143 000352 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-| 95.33% [143/150 25:46<01:15]\n",
      "144 000353 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-| 96.00% [144/150 25:50<01:04]\n",
      "145 000354 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-| 96.67% [145/150 25:59<00:53]\n",
      "146 000355 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-| 97.33% [146/150 26:17<00:43]\n",
      "147 000356 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-| 98.00% [147/150 26:20<00:32]\n",
      "148 000357 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-| 98.67% [148/150 26:24<00:21]\n",
      "149 000358 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ-| 99.33% [149/150 26:48<00:10]\n",
      " |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.00% [150/150 27:09<00:00]\n",
      "spatial, temporal, sigma: 0.5 0.5 19\n",
      "best_auc_local: 0.7630717610288131\n",
      "\n",
      "local, global, sigma: 0.9 0.1 19\n",
      "best_auc_total: 0.7639473457347853\n"
     ]
    }
   ],
   "source": [
    "!python Memorization/run.py \\\n",
    "    --work_num=0 --consecutive=4 --dataset=iitb --cnl_pool=64 \\\n",
    "    --spatial_f_coreset=0.1 --temporal_f_coreset=0.1 --highlevel_f_coreset=0.1 \\\n",
    "    --save_memory=False "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dvaa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
